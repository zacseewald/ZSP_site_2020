{"ast":null,"code":"'use strict';\n\nvar _taggedTemplateLiteral = require(\"/Users/zs/Desktop/ZSP_site_2020/node_modules/@babel/runtime/helpers/taggedTemplateLiteral\");\n\nvar _classCallCheck = require(\"/Users/zs/Desktop/ZSP_site_2020/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _possibleConstructorReturn = require(\"/Users/zs/Desktop/ZSP_site_2020/node_modules/@babel/runtime/helpers/possibleConstructorReturn\");\n\nvar _getPrototypeOf = require(\"/Users/zs/Desktop/ZSP_site_2020/node_modules/@babel/runtime/helpers/getPrototypeOf\");\n\nvar _inherits = require(\"/Users/zs/Desktop/ZSP_site_2020/node_modules/@babel/runtime/helpers/inherits\");\n\nvar _wrapNativeSuper = require(\"/Users/zs/Desktop/ZSP_site_2020/node_modules/@babel/runtime/helpers/wrapNativeSuper\");\n\nfunction _templateObject() {\n  var data = _taggedTemplateLiteral([\"No cache entry for `\", \"` found in `\", \"`\"], [\"No cache entry for \\\\`\", \"\\\\` found in \\\\`\", \"\\\\`\"]);\n\n  _templateObject = function _templateObject() {\n    return data;\n  };\n\n  return data;\n}\n\nvar BB = require('bluebird');\n\nvar contentPath = require('./content/path');\n\nvar crypto = require('crypto');\n\nvar figgyPudding = require('figgy-pudding');\n\nvar fixOwner = require('./util/fix-owner');\n\nvar fs = require('graceful-fs');\n\nvar hashToSegments = require('./util/hash-to-segments');\n\nvar ms = require('mississippi');\n\nvar path = require('path');\n\nvar ssri = require('ssri');\n\nvar Y = require('./util/y.js');\n\nvar indexV = require('../package.json')['cache-version'].index;\n\nvar appendFileAsync = BB.promisify(fs.appendFile);\nvar readFileAsync = BB.promisify(fs.readFile);\nvar readdirAsync = BB.promisify(fs.readdir);\nvar concat = ms.concat;\nvar from = ms.from;\n\nmodule.exports.NotFoundError =\n/*#__PURE__*/\nfunction (_Error) {\n  _inherits(NotFoundError, _Error);\n\n  function NotFoundError(cache, key) {\n    var _this;\n\n    _classCallCheck(this, NotFoundError);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(NotFoundError).call(this, Y(_templateObject(), key, cache)));\n    _this.code = 'ENOENT';\n    _this.cache = cache;\n    _this.key = key;\n    return _this;\n  }\n\n  return NotFoundError;\n}(_wrapNativeSuper(Error));\n\nvar IndexOpts = figgyPudding({\n  metadata: {},\n  size: {},\n  uid: {},\n  gid: {}\n});\nmodule.exports.insert = insert;\n\nfunction insert(cache, key, integrity, opts) {\n  opts = IndexOpts(opts);\n  var bucket = bucketPath(cache, key);\n  var entry = {\n    key: key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size: opts.size,\n    metadata: opts.metadata\n  };\n  return fixOwner.mkdirfix(path.dirname(bucket), opts.uid, opts.gid).then(function () {\n    var stringified = JSON.stringify(entry); // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with this.\n\n    return appendFileAsync(bucket, \"\\n\".concat(hashEntry(stringified), \"\\t\").concat(stringified));\n  }).then(function () {\n    return fixOwner.chownr(bucket, opts.uid, opts.gid);\n  }).catch({\n    code: 'ENOENT'\n  }, function () {// There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }).then(function () {\n    return formatEntry(cache, entry);\n  });\n}\n\nmodule.exports.insert.sync = insertSync;\n\nfunction insertSync(cache, key, integrity, opts) {\n  opts = IndexOpts(opts);\n  var bucket = bucketPath(cache, key);\n  var entry = {\n    key: key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size: opts.size,\n    metadata: opts.metadata\n  };\n  fixOwner.mkdirfix.sync(path.dirname(bucket), opts.uid, opts.gid);\n  var stringified = JSON.stringify(entry);\n  fs.appendFileSync(bucket, \"\\n\".concat(hashEntry(stringified), \"\\t\").concat(stringified));\n\n  try {\n    fixOwner.chownr.sync(bucket, opts.uid, opts.gid);\n  } catch (err) {\n    if (err.code !== 'ENOENT') {\n      throw err;\n    }\n  }\n\n  return formatEntry(cache, entry);\n}\n\nmodule.exports.find = find;\n\nfunction find(cache, key) {\n  var bucket = bucketPath(cache, key);\n  return bucketEntries(bucket).then(function (entries) {\n    return entries.reduce(function (latest, next) {\n      if (next && next.key === key) {\n        return formatEntry(cache, next);\n      } else {\n        return latest;\n      }\n    }, null);\n  }).catch(function (err) {\n    if (err.code === 'ENOENT') {\n      return null;\n    } else {\n      throw err;\n    }\n  });\n}\n\nmodule.exports.find.sync = findSync;\n\nfunction findSync(cache, key) {\n  var bucket = bucketPath(cache, key);\n\n  try {\n    return bucketEntriesSync(bucket).reduce(function (latest, next) {\n      if (next && next.key === key) {\n        return formatEntry(cache, next);\n      } else {\n        return latest;\n      }\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') {\n      return null;\n    } else {\n      throw err;\n    }\n  }\n}\n\nmodule.exports.delete = del;\n\nfunction del(cache, key, opts) {\n  return insert(cache, key, null, opts);\n}\n\nmodule.exports.delete.sync = delSync;\n\nfunction delSync(cache, key, opts) {\n  return insertSync(cache, key, null, opts);\n}\n\nmodule.exports.lsStream = lsStream;\n\nfunction lsStream(cache) {\n  var indexDir = bucketDir(cache);\n  var stream = from.obj(); // \"/cachename/*\"\n\n  readdirOrEmpty(indexDir).map(function (bucket) {\n    var bucketPath = path.join(indexDir, bucket); // \"/cachename/<bucket 0xFF>/*\"\n\n    return readdirOrEmpty(bucketPath).map(function (subbucket) {\n      var subbucketPath = path.join(bucketPath, subbucket); // \"/cachename/<bucket 0xFF>/<bucket 0xFF>/*\"\n\n      return readdirOrEmpty(subbucketPath).map(function (entry) {\n        var getKeyToEntry = bucketEntries(path.join(subbucketPath, entry)).reduce(function (acc, entry) {\n          acc.set(entry.key, entry);\n          return acc;\n        }, new Map());\n        return getKeyToEntry.then(function (reduced) {\n          var _iteratorNormalCompletion = true;\n          var _didIteratorError = false;\n          var _iteratorError = undefined;\n\n          try {\n            for (var _iterator = reduced.values()[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {\n              var _entry = _step.value;\n              var formatted = formatEntry(cache, _entry);\n              formatted && stream.push(formatted);\n            }\n          } catch (err) {\n            _didIteratorError = true;\n            _iteratorError = err;\n          } finally {\n            try {\n              if (!_iteratorNormalCompletion && _iterator.return != null) {\n                _iterator.return();\n              }\n            } finally {\n              if (_didIteratorError) {\n                throw _iteratorError;\n              }\n            }\n          }\n        }).catch({\n          code: 'ENOENT'\n        }, nop);\n      });\n    });\n  }).then(function () {\n    stream.push(null);\n  }, function (err) {\n    stream.emit('error', err);\n  });\n  return stream;\n}\n\nmodule.exports.ls = ls;\n\nfunction ls(cache) {\n  return BB.fromNode(function (cb) {\n    lsStream(cache).on('error', cb).pipe(concat(function (entries) {\n      cb(null, entries.reduce(function (acc, xs) {\n        acc[xs.key] = xs;\n        return acc;\n      }, {}));\n    }));\n  });\n}\n\nfunction bucketEntries(bucket, filter) {\n  return readFileAsync(bucket, 'utf8').then(function (data) {\n    return _bucketEntries(data, filter);\n  });\n}\n\nfunction bucketEntriesSync(bucket, filter) {\n  var data = fs.readFileSync(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\n\nfunction _bucketEntries(data, filter) {\n  var entries = [];\n  data.split('\\n').forEach(function (entry) {\n    if (!entry) {\n      return;\n    }\n\n    var pieces = entry.split('\\t');\n\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return;\n    }\n\n    var obj;\n\n    try {\n      obj = JSON.parse(pieces[1]);\n    } catch (e) {\n      // Entry is corrupted!\n      return;\n    }\n\n    if (obj) {\n      entries.push(obj);\n    }\n  });\n  return entries;\n}\n\nmodule.exports._bucketDir = bucketDir;\n\nfunction bucketDir(cache) {\n  return path.join(cache, \"index-v\".concat(indexV));\n}\n\nmodule.exports._bucketPath = bucketPath;\n\nfunction bucketPath(cache, key) {\n  var hashed = hashKey(key);\n  return path.join.apply(path, [bucketDir(cache)].concat(hashToSegments(hashed)));\n}\n\nmodule.exports._hashKey = hashKey;\n\nfunction hashKey(key) {\n  return hash(key, 'sha256');\n}\n\nmodule.exports._hashEntry = hashEntry;\n\nfunction hashEntry(str) {\n  return hash(str, 'sha1');\n}\n\nfunction hash(str, digest) {\n  return crypto.createHash(digest).update(str).digest('hex');\n}\n\nfunction formatEntry(cache, entry) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity) {\n    return null;\n  }\n\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: contentPath(cache, entry.integrity),\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata\n  };\n}\n\nfunction readdirOrEmpty(dir) {\n  return readdirAsync(dir).catch({\n    code: 'ENOENT'\n  }, function () {\n    return [];\n  }).catch({\n    code: 'ENOTDIR'\n  }, function () {\n    return [];\n  });\n}\n\nfunction nop() {}","map":null,"metadata":{},"sourceType":"script"}